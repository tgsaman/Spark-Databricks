{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the following data into a spark data frame:\n",
    "    /FileStore/sample/employees.txt\n",
    "\n",
    "    \n",
    "    You can also view the file here:\n",
    "https://gitlab.com/opstar/share20/-/raw/master/employees.txt\n",
    "\n",
    "2. Apply the correct column names using the header option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = spark.read.format('csv') \\\n",
    "  .option('delimiter','|') \\\n",
    "  .option('header','true') \\\n",
    "  .option('inferSchema','false') \\\n",
    "  .load('/FileStore/tables/employees.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = spark.read.format('csv') \\\n",
    "  .option('delimiter','|') \\\n",
    "  .option('header','true') \\\n",
    "  .option('inferSchema','true') \\\n",
    "  .load('/FileStore/sample/employees.txt')\n",
    "\n",
    "#only difference: inferschema is true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a new dataframe without the phone attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = e.drop('phone') \n",
    "f.show()\n",
    "\n",
    "#Because this is Python, the variable e could be overwritten. \n",
    "#However, overwriting a dataframe is bad form\n",
    "\n",
    "e.selectExpr('left(phone,3) AS area')\\\n",
    "        .groupBy('area')\\\n",
    "        .agg(count('*')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.where(e.hire_date < '2016-06-01').groupBy(e.manager_id*100).agg(count('*')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.agg(avg('manager_id')).show()\n",
    "\n",
    "e.select('manager_id').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, avg, min, countDistinct\n",
    "\n",
    "# SELECT manager_id, MIN(hire_date) FROM e GROUP BY manager_id\n",
    "\n",
    "e.groupBy('manager_id')\\\n",
    "    .agg(\n",
    "        min('hire_date')\n",
    "        , count('hire_date').alias('cnt')\n",
    "        , countDistinct('hire_date').alias('dcnt')\n",
    "        ).show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
